{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=read_data_set('data/snli_1.0_train.txt')\n",
    "dev=read_data_set('data/snli_1.0_dev.txt')\n",
    "text=read_data_set('data/snli_1.0_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import importlib\n",
    "import random\n",
    "#from util import logger\n",
    "#import util.parameters as params\n",
    "#from util.data_processing import *\n",
    "#from util.evaluate import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "import json\n",
    "import collections\n",
    "#import parameters as params\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data_set(data_path):\n",
    "    \"\"\"\n",
    "    read dataset from data_path\n",
    "    return a dataset with 5 columns of tokens of sentence 1 and 2, sizes of tokens, and one hot vector as label\n",
    "    data with gold_label of \"-\" are removed\n",
    "    \"\"\"\n",
    "    \n",
    "    def tokenize_sentence(parse):\n",
    "        \"\"\"\n",
    "        Read the given parse string\n",
    "        return a list of token with NULL prepended\n",
    "        \"\"\"\n",
    "        parse = parse.lower()\n",
    "        tree = nltk.Tree.fromstring(parse)\n",
    "        token_list = tree.leaves()\n",
    "        token_list.insert(0,\"NULL\")\n",
    "        return token_list\n",
    "    \n",
    "    def tokenize_sentence_from_binary_parse(parse):\n",
    "        \"\"\"\n",
    "        @param parse: a binary parse of the sentence\n",
    "        @return: token of the parsed sentence\n",
    "        \"\"\"\n",
    "        token_list = [\"<NULL>\"]\n",
    "        if parse:\n",
    "            token_list  = token_list + parse.lower().replace(\"(\", \"\").replace(\")\", \"\").strip().split()\n",
    "        return token_list\n",
    "        \n",
    "    \n",
    "    def label_function (label):\n",
    "        \"\"\"\n",
    "        Read a label of entailment, contradiction, and neutral\n",
    "        Return a onehot vector of [1,0,0] for entailment, [0,1,0] for contradiction, and  [0,0,1] for neutral\n",
    "        \"\"\"\n",
    "        labels = {'entailment':0, 'contradiction':1, 'neutral':2}\n",
    "        try:\n",
    "            onehot = [0,0,0]\n",
    "            onehot[labels[label]] = 1\n",
    "            return onehot\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    data = pd.read_csv(data_path,delimiter=\"\\t\")\n",
    "    data = data[data[\"gold_label\"] != \"-\"]\n",
    "    \n",
    "    data['sentence1_token'] = data.apply(lambda row: tokenize_sentence_from_binary_parse(row['sentence1_binary_parse']), axis=1)\n",
    "    data['sentence2_token'] = data.apply(lambda row: tokenize_sentence_from_binary_parse(row['sentence2_binary_parse']), axis=1)\n",
    "    \n",
    "    data['sentence1_size'] =  data.apply(lambda row: len(row['sentence1_token']), axis=1)\n",
    "    data['sentence2_size'] = data.apply(lambda row: len(row['sentence2_token']), axis=1)\n",
    "    data['max_size'] = data.apply(lambda row: max(row['sentence1_size'], row['sentence2_size']), axis=1)\n",
    "    data['min_size'] = data.apply(lambda row: min(row['sentence1_size'], row['sentence2_size']), axis=1)\n",
    "    \n",
    "    data = data[data[\"min_size\"] > 1]\n",
    "    \n",
    "    data['onehot_label'] = data.apply(lambda row: label_function(row['gold_label']), axis=1)\n",
    "    return data[['sentence1_token', 'sentence2_token', 'sentence1_size', 'sentence2_size', 'onehot_label', 'max_size']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#FIXED_PARAMETERS = params.load_parameters()\n",
    "\n",
    "LABEL_MAP = {\n",
    "    \"entailment\": 0,\n",
    "    \"neutral\": 1,\n",
    "    \"contradiction\": 2,\n",
    "    \"hidden\": 0\n",
    "}\n",
    "\n",
    "PADDING = \"<PAD>\"\n",
    "UNKNOWN = \"<UNK>\"\n",
    "\n",
    "def load_nli_data(path, snli=False):\n",
    "    \"\"\"\n",
    "    Load MultiNLI or SNLI data.\n",
    "    If the \"snli\" parameter is set to True, a genre label of snli will be assigned to the data. \n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            loaded_example = json.loads(line)\n",
    "            if loaded_example[\"gold_label\"] not in LABEL_MAP:\n",
    "                continue\n",
    "            loaded_example[\"label\"] = LABEL_MAP[loaded_example[\"gold_label\"]]\n",
    "            if snli:\n",
    "                loaded_example[\"genre\"] = \"snli\"\n",
    "            data.append(loaded_example)\n",
    "        random.seed(1)\n",
    "        random.shuffle(data)\n",
    "    return data\n",
    "\n",
    "\n",
    "def tokenize(string):\n",
    "    string = re.sub(r'\\(|\\)', '', string)\n",
    "    return string.split()\n",
    "\n",
    "def build_dictionary(training_datasets):\n",
    "    \"\"\"\n",
    "    Extract vocabulary and build dictionary.\n",
    "    \"\"\"  \n",
    "    word_counter = collections.Counter()\n",
    "    for i, dataset in enumerate(training_datasets):\n",
    "        for example in dataset:\n",
    "            word_counter.update(tokenize(example['sentence1_binary_parse']))\n",
    "            word_counter.update(tokenize(example['sentence2_binary_parse']))\n",
    "        \n",
    "    vocabulary = set([word for word in word_counter])\n",
    "    vocabulary = list(vocabulary)\n",
    "    vocabulary = [PADDING, UNKNOWN] + vocabulary\n",
    "        \n",
    "    word_indices = dict(zip(vocabulary, range(len(vocabulary))))\n",
    "\n",
    "    return word_indices\n",
    "\n",
    "def sentences_to_padded_index_sequences(word_indices, datasets):\n",
    "    \"\"\"\n",
    "    Annotate datasets with feature vectors. Adding right-sided padding. \n",
    "    \"\"\"\n",
    "    for i, dataset in enumerate(datasets):\n",
    "        for example in dataset:\n",
    "            for sentence in ['sentence1_binary_parse', 'sentence2_binary_parse']:\n",
    "                example[sentence + '_index_sequence'] = np.zeros((FIXED_PARAMETERS[\"seq_length\"]), dtype=np.int32)\n",
    "\n",
    "                token_sequence = tokenize(example[sentence])\n",
    "                padding = FIXED_PARAMETERS[\"seq_length\"] - len(token_sequence)\n",
    "\n",
    "                for i in range(FIXED_PARAMETERS[\"seq_length\"]):\n",
    "                    if i >= len(token_sequence):\n",
    "                        index = word_indices[PADDING]\n",
    "                    else:\n",
    "                        if token_sequence[i] in word_indices:\n",
    "                            index = word_indices[token_sequence[i]]\n",
    "                        else:\n",
    "                            index = word_indices[UNKNOWN]\n",
    "                    example[sentence + '_index_sequence'][i] = index\n",
    "\n",
    "\n",
    "def loadEmbedding_zeros(path, word_indices):\n",
    "    \"\"\"\n",
    "    Load GloVe embeddings. Initializng OOV words to vector of zeros.\n",
    "    \"\"\"\n",
    "    emb = np.zeros((len(word_indices), FIXED_PARAMETERS[\"word_embedding_dim\"]), dtype='float32')\n",
    "    \n",
    "    with open(path, 'r') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if FIXED_PARAMETERS[\"embeddings_to_load\"] != None:\n",
    "                if i >= FIXED_PARAMETERS[\"embeddings_to_load\"]:\n",
    "                    break\n",
    "            \n",
    "            s = line.split()\n",
    "            if s[0] in word_indices:\n",
    "                emb[word_indices[s[0]], :] = np.asarray(s[1:])\n",
    "\n",
    "    return emb\n",
    "\n",
    "\n",
    "def loadEmbedding_rand(path, word_indices):\n",
    "    \"\"\"\n",
    "    Load GloVe embeddings. Doing a random normal initialization for OOV words.\n",
    "    \"\"\"\n",
    "    n = len(word_indices)\n",
    "    m = FIXED_PARAMETERS[\"word_embedding_dim\"]\n",
    "    emb = np.empty((n, m), dtype=np.float32)\n",
    "\n",
    "    emb[:,:] = np.random.normal(size=(n,m))\n",
    "\n",
    "    # Explicitly assign embedding of <PAD> to be zeros.\n",
    "    emb[0:2, :] = np.zeros((1,m), dtype=\"float32\")\n",
    "    \n",
    "    with open(path, 'r') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if FIXED_PARAMETERS[\"embeddings_to_load\"] != None:\n",
    "                if i >= FIXED_PARAMETERS[\"embeddings_to_load\"]:\n",
    "                    break\n",
    "            \n",
    "            s = line.split()\n",
    "            if s[0] in word_indices:\n",
    "                emb[word_indices[s[0]], :] = np.asarray(s[1:])\n",
    "\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FIXED_PARAMETERS = params.load_parameters()\n",
    "modname = FIXED_PARAMETERS[\"model_name\"]\n",
    "logpath = os.path.join(FIXED_PARAMETERS[\"log_path\"], modname) + \".log\"\n",
    "logger = logger.Logger(logpath)\n",
    "\n",
    "model = FIXED_PARAMETERS[\"model_type\"]\n",
    "\n",
    "module = importlib.import_module(\".\".join(['models', model])) \n",
    "MyModel = getattr(module, 'MyModel')\n",
    "\n",
    "# Logging parameter settings at each launch of training script\n",
    "# This will help ensure nothing goes awry in reloading a model and we consistenyl use the same hyperparameter settings. \n",
    "logger.Log(\"FIXED_PARAMETERS\\n %s\" % FIXED_PARAMETERS)\n",
    "\n",
    "######################### LOAD DATA #############################\n",
    "\n",
    "logger.Log(\"Loading data\")\n",
    "training_snli = load_nli_data(FIXED_PARAMETERS[\"training_snli\"], snli=True)\n",
    "dev_snli = load_nli_data(FIXED_PARAMETERS[\"dev_snli\"], snli=True)\n",
    "test_snli = load_nli_data(FIXED_PARAMETERS[\"test_snli\"], snli=True)\n",
    "\n",
    "training_mnli = load_nli_data(FIXED_PARAMETERS[\"training_mnli\"])\n",
    "dev_matched = load_nli_data(FIXED_PARAMETERS[\"dev_matched\"])\n",
    "dev_mismatched = load_nli_data(FIXED_PARAMETERS[\"dev_mismatched\"])\n",
    "test_matched = load_nli_data(FIXED_PARAMETERS[\"test_matched\"])\n",
    "test_mismatched = load_nli_data(FIXED_PARAMETERS[\"test_mismatched\"])\n",
    "\n",
    "if 'temp.jsonl' in FIXED_PARAMETERS[\"test_matched\"]:\n",
    "    # Removing temporary empty file that was created in parameters.py\n",
    "    os.remove(FIXED_PARAMETERS[\"test_matched\"])\n",
    "    logger.Log(\"Created and removed empty file called temp.jsonl since test set is not available.\")\n",
    "\n",
    "dictpath = os.path.join(FIXED_PARAMETERS[\"log_path\"], modname) + \".p\"\n",
    "\n",
    "if not os.path.isfile(dictpath): \n",
    "    logger.Log(\"Building dictionary\")\n",
    "    word_indices = build_dictionary([training_snli])\n",
    "    logger.Log(\"Padding and indexifying sentences\")\n",
    "    sentences_to_padded_index_sequences(word_indices, [training_snli, training_mnli, dev_matched, dev_mismatched, dev_snli, test_snli, test_matched, test_mismatched])\n",
    "    pickle.dump(word_indices, open(dictpath, \"wb\"))\n",
    "\n",
    "else:\n",
    "    logger.Log(\"Loading dictionary from %s\" % (dictpath))\n",
    "    word_indices = pickle.load(open(dictpath, \"rb\"))\n",
    "    logger.Log(\"Padding and indexifying sentences\")\n",
    "    sentences_to_padded_index_sequences(word_indices, [training_mnli, training_snli, dev_matched, dev_mismatched, dev_snli, test_snli, test_matched, test_mismatched])\n",
    "\n",
    "logger.Log(\"Loading embeddings\")\n",
    "loaded_embeddings = loadEmbedding_rand(FIXED_PARAMETERS[\"embedding_data_path\"], word_indices)\n",
    "\n",
    "class modelClassifier:\n",
    "    def __init__(self, seq_length):\n",
    "        ## Define hyperparameters\n",
    "        self.learning_rate =  FIXED_PARAMETERS[\"learning_rate\"]\n",
    "        self.display_epoch_freq = 1\n",
    "        self.display_step_freq = 50\n",
    "        self.embedding_dim = FIXED_PARAMETERS[\"word_embedding_dim\"]\n",
    "        self.dim = FIXED_PARAMETERS[\"hidden_embedding_dim\"]\n",
    "        self.batch_size = FIXED_PARAMETERS[\"batch_size\"]\n",
    "        self.emb_train = FIXED_PARAMETERS[\"emb_train\"]\n",
    "        self.keep_rate = FIXED_PARAMETERS[\"keep_rate\"]\n",
    "        self.sequence_length = FIXED_PARAMETERS[\"seq_length\"] \n",
    "        self.alpha = FIXED_PARAMETERS[\"alpha\"]\n",
    "\n",
    "        logger.Log(\"Building model from %s.py\" %(model))\n",
    "        self.model = MyModel(seq_length=self.sequence_length, emb_dim=self.embedding_dim,  hidden_dim=self.dim, embeddings=loaded_embeddings, emb_train=self.emb_train)\n",
    "\n",
    "        # Perform gradient descent with Adam\n",
    "        self.optimizer = tf.train.AdamOptimizer(self.learning_rate, beta1=0.9, beta2=0.999).minimize(self.model.total_cost)\n",
    "\n",
    "        # Boolean stating that training has not been completed, \n",
    "        self.completed = False \n",
    "\n",
    "        # tf things: initialize variables and create placeholder for session\n",
    "        logger.Log(\"Initializing variables\")\n",
    "        self.init = tf.global_variables_initializer()\n",
    "        self.sess = None\n",
    "        self.saver = tf.train.Saver()\n",
    "\n",
    "\n",
    "    def get_minibatch(self, dataset, start_index, end_index):\n",
    "        indices = range(start_index, end_index)\n",
    "        premise_vectors = np.vstack([dataset[i]['sentence1_binary_parse_index_sequence'] for i in indices])\n",
    "        hypothesis_vectors = np.vstack([dataset[i]['sentence2_binary_parse_index_sequence'] for i in indices])\n",
    "        genres = [dataset[i]['genre'] for i in indices]\n",
    "        labels = [dataset[i]['label'] for i in indices]\n",
    "        return premise_vectors, hypothesis_vectors, labels, genres\n",
    "\n",
    "\n",
    "    def train(self, train_mnli, train_snli, dev_mat, dev_mismat, dev_snli):        \n",
    "        self.sess = tf.Session()\n",
    "        self.sess.run(self.init)\n",
    "\n",
    "        self.step = 1\n",
    "        self.epoch = 0\n",
    "        self.best_dev_snli = 0.\n",
    "        self.best_strain_acc = 0.\n",
    "        self.last_train_acc = [.001, .001, .001, .001, .001]\n",
    "        self.best_step = 0\n",
    "\n",
    "        # Restore most recent checkpoint if it exists. \n",
    "        # Also restore values for best dev-set accuracy and best training-set accuracy.\n",
    "        ckpt_file = os.path.join(FIXED_PARAMETERS[\"ckpt_path\"], modname) + \".ckpt\"\n",
    "        if os.path.isfile(ckpt_file + \".meta\"):\n",
    "            if os.path.isfile(ckpt_file + \"_best.meta\"):\n",
    "                self.saver.restore(self.sess, (ckpt_file + \"_best\"))\n",
    "                best_dev_mat, dev_cost_mat = evaluate_classifier(self.classify, dev_mat, self.batch_size)\n",
    "                best_dev_mismat, dev_cost_mismat = evaluate_classifier(self.classify, dev_mismat, self.batch_size)\n",
    "                self.best_dev_snli, dev_cost_snli = evaluate_classifier(self.classify, dev_snli, self.batch_size)\n",
    "                self.best_strain_acc, strain_cost = evaluate_classifier(self.classify, train_snli[0:5000], self.batch_size)\n",
    "                logger.Log(\"Restored best matched-dev acc: %f\\n Restored best mismatched-dev acc: %f\\n Restored best SNLI-dev acc: %f\\n Restored best SNLI train acc: %f\" %(best_dev_mat, best_dev_mismat, self.best_dev_snli,  self.best_strain_acc))\n",
    "\n",
    "            self.saver.restore(self.sess, ckpt_file)\n",
    "            logger.Log(\"Model restored from file: %s\" % ckpt_file)\n",
    "\n",
    "        training_data = train_snli\n",
    "\n",
    "        ### Training cycle\n",
    "        logger.Log(\"Training...\")\n",
    "\n",
    "        while True:\n",
    "            random.shuffle(training_data)\n",
    "            avg_cost = 0.\n",
    "            total_batch = int(len(training_data) / self.batch_size)\n",
    "            \n",
    "            # Loop over all batches in epoch\n",
    "            for i in range(total_batch):\n",
    "                # Assemble a minibatch of the next B examples\n",
    "                minibatch_premise_vectors, minibatch_hypothesis_vectors, minibatch_labels, minibatch_genres = self.get_minibatch(\n",
    "                    training_data, self.batch_size * i, self.batch_size * (i + 1))\n",
    "                \n",
    "                # Run the optimizer to take a gradient step, and also fetch the value of the \n",
    "                # cost function for logging\n",
    "                feed_dict = {self.model.premise_x: minibatch_premise_vectors,\n",
    "                                self.model.hypothesis_x: minibatch_hypothesis_vectors,\n",
    "                                self.model.y: minibatch_labels, \n",
    "                                self.model.keep_rate_ph: self.keep_rate}\n",
    "                _, c = self.sess.run([self.optimizer, self.model.total_cost], feed_dict)\n",
    "\n",
    "                # Since a single epoch can take a  ages for larger models (ESIM),\n",
    "                #  we'll print accuracy every 50 steps\n",
    "                if self.step % self.display_step_freq == 0:\n",
    "                    dev_acc_mat, dev_cost_mat = evaluate_classifier(self.classify, dev_mat, self.batch_size)\n",
    "                    dev_acc_mismat, dev_cost_mismat = evaluate_classifier(self.classify, dev_mismat, self.batch_size)\n",
    "                    dev_acc_snli, dev_cost_snli = evaluate_classifier(self.classify, dev_snli, self.batch_size)\n",
    "                    strain_acc, strain_cost = evaluate_classifier(self.classify, train_snli[0:5000], self.batch_size)\n",
    "\n",
    "                    logger.Log(\"Step: %i\\t Dev-matched acc: %f\\t Dev-mismatched acc: %f\\t Dev-SNLI acc: %f\\t SNLI train acc: %f\" %(self.step, dev_acc_mat, dev_acc_mismat, dev_acc_snli, strain_acc))\n",
    "                    logger.Log(\"Step: %i\\t Dev-matched cost: %f\\t Dev-mismatched cost: %f\\t Dev-SNLI cost: %f\\t SNLI train cost: %f\" %(self.step, dev_cost_mat, dev_cost_mismat, dev_cost_snli, strain_cost))\n",
    "\n",
    "                if self.step % 500 == 0:\n",
    "                    self.saver.save(self.sess, ckpt_file)\n",
    "                    best_test = 100 * (1 - self.best_dev_snli / dev_acc_snli)\n",
    "                    if best_test > 0.04:\n",
    "                        self.saver.save(self.sess, ckpt_file + \"_best\")\n",
    "                        self.best_dev_snli = dev_acc_snli\n",
    "                        self.best_strain_acc = strain_acc\n",
    "                        self.best_step = self.step\n",
    "                        logger.Log(\"Checkpointing with new best SNLI-dev accuracy: %f\" %(self.best_dev_snli))\n",
    "\n",
    "                self.step += 1\n",
    "\n",
    "                # Compute average loss\n",
    "                avg_cost += c / (total_batch * self.batch_size)\n",
    "                                \n",
    "            # Display some statistics about the epoch\n",
    "            if self.epoch % self.display_epoch_freq == 0:\n",
    "                logger.Log(\"Epoch: %i\\t Avg. Cost: %f\" %(self.epoch+1, avg_cost))\n",
    "            \n",
    "            self.epoch += 1 \n",
    "            self.last_train_acc[(self.epoch % 5) - 1] = strain_acc\n",
    "\n",
    "            # Early stopping\n",
    "            progress = 1000 * (sum(self.last_train_acc)/(5 * min(self.last_train_acc)) - 1) \n",
    "\n",
    "            if (progress < 0.1) or (self.step > self.best_step + 30000):\n",
    "                logger.Log(\"Best snli-dev accuracy: %s\" %(self.best_dev_snli))\n",
    "                logger.Log(\"MultiNLI Train accuracy: %s\" %(self.best_strain_acc))\n",
    "                self.completed = True\n",
    "                break\n",
    "\n",
    "    def restore(self, best=True):\n",
    "        if True:\n",
    "            path = os.path.join(FIXED_PARAMETERS[\"ckpt_path\"], modname) + \".ckpt_best\"\n",
    "        else:\n",
    "            path = os.path.join(FIXED_PARAMETERS[\"ckpt_path\"], modname) + \".ckpt\"\n",
    "        self.sess = tf.Session()\n",
    "        self.sess.run(self.init)\n",
    "        self.saver.restore(self.sess, path)\n",
    "        logger.Log(\"Model restored from file: %s\" % path)\n",
    "\n",
    "    def classify(self, examples):\n",
    "        # This classifies a list of examples\n",
    "        total_batch = int(len(examples) / self.batch_size)\n",
    "        logits = np.empty(3)\n",
    "        genres = []\n",
    "        for i in range(total_batch):\n",
    "            minibatch_premise_vectors, minibatch_hypothesis_vectors, minibatch_labels, minibatch_genres = self.get_minibatch(\n",
    "                examples, self.batch_size * i, self.batch_size * (i + 1))\n",
    "            feed_dict = {self.model.premise_x: minibatch_premise_vectors, \n",
    "                                self.model.hypothesis_x: minibatch_hypothesis_vectors,\n",
    "                                self.model.y: minibatch_labels, \n",
    "                                self.model.keep_rate_ph: 1.0}\n",
    "            genres += minibatch_genres\n",
    "            logit, cost = self.sess.run([self.model.logits, self.model.total_cost], feed_dict)\n",
    "            logits = np.vstack([logits, logit])\n",
    "\n",
    "        return genres, np.argmax(logits[1:], axis=1), cost\n",
    "\n",
    "\n",
    "classifier = modelClassifier(FIXED_PARAMETERS[\"seq_length\"])\n",
    "\n",
    "\"\"\"\n",
    "Either train the model and then run it on the test-sets or \n",
    "load the best checkpoint and get accuracy on the test set. Default setting is to train the model.\n",
    "\"\"\"\n",
    "\n",
    "test = params.train_or_test()\n",
    "\n",
    "# While test-set isn't released, use dev-sets for testing\n",
    "test_matched = dev_matched\n",
    "test_mismatched = dev_mismatched\n",
    "\n",
    "\n",
    "if test == False:\n",
    "    classifier.train(training_mnli, training_snli, dev_matched, dev_mismatched, dev_snli)\n",
    "    logger.Log(\"Acc on matched multiNLI dev-set: %s\" %(evaluate_classifier(classifier.classify, test_matched, FIXED_PARAMETERS[\"batch_size\"]))[0])\n",
    "    logger.Log(\"Acc on mismatched multiNLI dev-set: %s\" %(evaluate_classifier(classifier.classify, test_mismatched, FIXED_PARAMETERS[\"batch_size\"]))[0])\n",
    "    logger.Log(\"Acc on SNLI test-set: %s\" %(evaluate_classifier(classifier.classify, test_snli, FIXED_PARAMETERS[\"batch_size\"]))[0])\n",
    "else: \n",
    "    results = evaluate_final(classifier.restore, classifier.classify, [test_matched, test_mismatched, test_snli], FIXED_PARAMETERS[\"batch_size\"])\n",
    "    logger.Log(\"Acc on multiNLI matched dev-set: %s\" %(results[0]))\n",
    "    logger.Log(\"Acc on multiNLI mismatched dev-set: %s\" %(results[1]))\n",
    "    logger.Log(\"Acc on SNLI test set: %s\" %(results[2]))\n",
    "\n",
    "    # Results by genre,\n",
    "    logger.Log(\"Acc on matched genre dev-sets: %s\" %(evaluate_classifier_genre(classifier.classify, test_matched, FIXED_PARAMETERS[\"batch_size\"])[0]))\n",
    "    logger.Log(\"Acc on mismatched genres dev-sets: %s\" %(evaluate_classifier_genre(classifier.classify, test_mismatched, FIXED_PARAMETERS[\"batch_size\"])[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
